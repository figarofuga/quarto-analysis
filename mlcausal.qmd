---
title: "機械学習を用いた因果推論"
author: "Nozomi Niimi"
format: clean-typst
date: today
date-format: long
jupyter: python3
---

```{python}

import pandas as pd

lalonde_py = pd.read_csv("rawdata/lalonde.csv")

lalonde_py2 = pd.get_dummies(
    lalonde_py,
    columns=["race"],
    drop_first=True
)

```

# 因果推論 at glance

## 因果関係

- 医学研究の第一の目標と言っても過言ではない
- Aの薬を使うと患者の予後は良くなるか？
- 実際は口で言うほど簡単ではない

## 因果関係の考え方

- 大きく分けて2つの考え方がある
  - 潜在的アウトカムを考えるRubin流
  - DAGを作り、do operatorを使うPearl流
- 詳細は省くが、今回はPearl流のDAGを中心に考える

## 通常の統計学的手法

- 通常は交絡因子の調整により因果関係を推測する
<!-- Todo: DAGを作る -->

## 交絡因子の調整の方法

- 回帰
- Matching
- 層別化

## 例えば単純な回帰だと {.allowframebreaks .fragile}
```{python}
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
from stargazer.stargazer import Stargazer


fit_ols = smf.ols("re78 ~ treat + age + educ + race + married + nodegree + re74 + re75", data = lalonde_py)

res_ols = fit_ols.fit()

pd.read_html(res_ols.summary2().as_html())[1]

res_ols_sg = Stargazer([res_ols])

res_ols_sg.render_latex()
```

## Matchingだと

- 一番有名なのはPropensity score matching

```{python}

import numpy as np
import pandas as pd

from causalml.propensity import LogisticRegressionPropensityModel
from causalml.match import NearestNeighborMatch

# -----------------------
# 2) Estimate propensity score with Logistic Regression
# -----------------------

ps_model = LogisticRegressionPropensityModel()  
p_score = ps_model.fit_predict(lalonde_py2[["age", "educ", "married", "nodegree", "re74", "re75", "race_hispan", "race_white"]], lalonde_py2["treat"])

lalonde_py_pm = (
  lalonde_py2
  .assign(propensity_score = p_score)
  
)

# -----------------------
# 3) Propensity score matching (Nearest Neighbor)
# -----------------------
matcher = NearestNeighborMatch(
    caliper=0.05,     # PS差がこの範囲以内のみマッチ (例) :contentReference[oaicite:2]{index=2}
    replace=False,    # 置換なし
    ratio=1,          # 1:1 matching
    random_state=42
)

matched = matcher.match(
    data=lalonde_py_pm,
    treatment_col="treat",
    score_cols=["propensity_score"]  # ここにPS列名
)

print(matched.head())
print("matched size:", matched.shape)

# -----------------------
# 4) Simple ATT estimate on matched sample (difference in means)
# -----------------------
att = matched.loc[matched["treat"] == 1, "re78"].mean() - matched.loc[matched["treat"] == 0, "re78"].mean()
print("ATT (diff in means on matched sample):", att)

```


## DAGつき

```{python}
import pandas as pd
import dowhy
import networkx as nx
from dowhy import CausalModel

lalonde = pd.read_csv('rawdata/lalonde.csv')

lalonde_post = (pd.get_dummies(lalonde, 
                         columns=["race"], dtype=int)          
)

# 2. NetworkXでグラフを定義
causal_graph = nx.DiGraph()
# "age", "educ", "married", "nodegree", "re74", "re75", "race_black", "race_hispan", "race_white"
# ノードとエッジを追加 (交絡構造: Age -> Exercise, Age -> Health)
causal_graph.add_nodes_from(["treat", "age", "educ", "married", "nodegree", "re74", "re75", "race_black", "race_hispan", "race_white", "re78"])

causal_graph.add_edges_from([
    ('treat', 're78'),
    ('re74', 're75'),
    ('age', 'treat'), 
    ('age', 're78'),
    ('educ', 'treat'),
    ('educ', 're78'),
    ('married', 'treat'),
    ('married', 're78'),
    ('nodegree', 'treat'),
    ('nodegree', 're78'),
    ('re74', 'treat'),
    ('re75', 'treat'), 
    ('re75', 're78'), 
    ('race_black', 'treat'),
    ('race_black', 're74'),
    ('race_black', 're75'),
    ('race_black', 're78'),
    ('race_hispan', 'treat'),
    ('race_hispan', 're74'),
    ('race_hispan', 're75'),
    ('race_hispan', 're78'),
    ('race_white', 'treat'),
    ('race_white', 're74'),
    ('race_white', 're75'),
    ('race_white', 're78')
    
])

# 3. NetworkXオブジェクトをGML文字列に変換
# 注意: 文字列内の改行コードなどを整形して渡します
gml_string = "".join(nx.generate_gml(causal_graph))

# 4. モデルの定義
model = CausalModel(
    data=lalonde_post,
    treatment='treat',
    outcome='re78',
    graph=gml_string
)

# 5. グラフの確認
model.view_model()

model.summary()

identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)

print(identified_estimand)

causal_estimate = model.estimate_effect(identified_estimand,
        method_name="backdoor.propensity_score_matching")
        
print(causal_estimate)

res_random=model.refute_estimate(identified_estimand, causal_estimate, method_name="random_common_cause", show_progress_bar=True)

print(res_random)

```

## ここらへんの問題

- Misspecificationの問題
- Estimandの問題 = 治療効果の異質性

# 機械学習 at glance

## 機械学習とは


## 代表的な機械学習

- Logistic回帰
- tree-based model
  - Random forest
  - XGBoost
- Neural network


## 機械学習の強み

## 疑問

- 機械学習を用いて因果関係を推測出来るんじゃないか？

## 機械学習を用いた因果推論のPros and Cons

- Pros
  - モデルのMisspecificationを避けられる
  - 因果関係の異質性を柔軟に捉えられる
- Cons
  - Overfittingの問題
  - 解釈が難しい時がある
  - 信頼区間が出しにくい

## 機械学習の因果推論における使い方

- 交絡因子の調整で機械学習を用いる
  - AIPW, tlmeなど
- 因果をダイレクトに推論する学習機を作る
  - Meta-learner
- CATEを測定する
  - Causal forestなど

## 因果forest

<!-- ```{r}
library(dplyr)
library(grf)

X <- model.matrix(~ age + educ + race + married + nodegree + re74 + re75 + 0, data = dplyr::select(lalonde_r, -re78, -treat))
Y <- lalonde_r$re78
W <- lalonde_r$treat

fit_grf <- grf::causal_forest(X = X, Y = Y, W = W)

grf::average_treatment_effect(fit_grf, target.sample = "overlap")

``` -->


## python 




