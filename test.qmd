---
title: "Habits"
author: "John Doe"
format: html
---
```{python}

import pandas as pd
import polars as pl
import marginaleffects

lalonde = pd.read_csv("rawdata/lalonde.csv")
```


```{python}
import matplotlib.pyplot as plt
import seaborn as sns

lalonde_py = r.lalonde_r

lalonde_py.describe()

sns.scatterplot(data = lalonde_py, x = 're74', y = 're78', hue = 'treat')

plt.show()

```

```{python}
import statsmodels.formula.api as smf

formu = 're78 ~ treat + age + educ + race + married + nodegree + re74 + re75'

ols_fit = smf.ols(formula=formu, data = lalonde_py).fit()

ols_fit.summary()
```

```{python}
import pandas as pd
import dowhy
import networkx as nx
from dowhy import CausalModel

lalonde_post = (pd.get_dummies(lalonde, 
                         columns=["race"], dtype=int)          
)

# 2. NetworkXでグラフを定義
causal_graph = nx.DiGraph()
# "age", "educ", "married", "nodegree", "re74", "re75", "race_black", "race_hispan", "race_white"
# ノードとエッジを追加 (交絡構造: Age -> Exercise, Age -> Health)
causal_graph.add_nodes_from(["treat", "age", "educ", "married", "nodegree", "re74", "re75", "race_black", "race_hispan", "race_white", "re78"])

causal_graph.add_edges_from([
    ('treat', 're78'),
    ('re74', 're75'),
    ('age', 'treat'), 
    ('age', 're78'),
    ('educ', 'treat'),
    ('educ', 're78'),
    ('married', 'treat'),
    ('married', 're78'),
    ('nodegree', 'treat'),
    ('nodegree', 're78'),
    ('re74', 'treat'),
    ('re75', 'treat'), 
    ('re75', 're78'), 
    ('race_black', 'treat'),
    ('race_black', 're74'),
    ('race_black', 're75'),
    ('race_black', 're78'),
    ('race_hispan', 'treat'),
    ('race_hispan', 're74'),
    ('race_hispan', 're75'),
    ('race_hispan', 're78'),
    ('race_white', 'treat'),
    ('race_white', 're74'),
    ('race_white', 're75'),
    ('race_white', 're78')
    
])

# 3. NetworkXオブジェクトをGML文字列に変換
# 注意: 文字列内の改行コードなどを整形して渡します
gml_string = "".join(nx.generate_gml(causal_graph))

# 4. モデルの定義
model = CausalModel(
    data=lalonde_post,
    treatment='treat',
    outcome='re78',
    graph=gml_string
)

# 5. グラフの確認
model.view_model()

model.summary()

identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)

print(identified_estimand)

causal_estimate = model.estimate_effect(identified_estimand,
        method_name="backdoor.propensity_score_stratification")
        
print(causal_estimate)

res_random=model.refute_estimate(identified_estimand, causal_estimate, method_name="random_common_cause", show_progress_bar=True)

print(res_random)
```

### read data

```{python}
import pandas as pd
from econml.dml import LinearDML

lalonde = pd.read_csv("rawdata/lalonde.csv")

est = LinearDML()

X = lalonde.loc[:,["age", "married", "educ", "nodegree", "re74", "re75"]].to_numpy()

est.fit(lalonde['re78'], 
        lalonde['treat'], 
        X=X
        )
point = est.effect(X, T0=0, T1=1)

point = est.const_marginal_effect(X)
lb, ub = est.const_marginal_effect_interval(X, alpha=0.05)

```

```{python}

# Main imports
from econml.metalearners import TLearner, SLearner, XLearner, DomainAdaptationLearner

# Helper imports
import numpy as np
import pandas as pd
from numpy.random import binomial, multivariate_normal, normal, uniform
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.model_selection import train_test_split

lalonde = pd.read_csv("rawdata/lalonde.csv")

lalonde_post = (pd.get_dummies(lalonde, 
                         columns=["race"], dtype=int)          
)

X = lalonde_post.loc[:,["age", "married", "educ", "nodegree", "re74", "re75", "race_black", "race_hispan", "race_white"]]
y = lalonde_post['re78']
T = lalonde_post['treat']
n = lalonde_post.shape[0]

X_train, X_test, y_train, y_test = train_test_split(
    X, 
    y, 
    test_size=0.2, 
    random_state=42, 
    stratify=T
    )

T_train = T.loc[y_train.index]
T_test = T.loc[y_test.index]

# Instantiate T learner
models = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))
T_learner = TLearner(models=models)
# Train T_learner
T_learner.fit(y_train, T_train, X=X_train)
# Estimate treatment effects on test data
T_te = T_learner.effect(X_test)

# Instantiate S learner
overall_model = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(491/100))
S_learner = SLearner(overall_model=overall_model)
# Train S_learner
S_learner.fit(y_train, T_train, X=X_train)
# Estimate treatment effects on test data
S_te = S_learner.effect(X_test)

# Instantiate X learner
models = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))
propensity_model = RandomForestClassifier(n_estimators=100, max_depth=6,
                                                  min_samples_leaf=int(n/100))
X_learner = XLearner(models=models, propensity_model=propensity_model)
# Train X_learner
X_learner.fit(y_train, T_train, X=X_train)
# Estimate treatment effects on test data
X_te = X_learner.effect(X_test)

# Instantiate Domain Adaptation learner
models = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))
final_models = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))
propensity_model = RandomForestClassifier(n_estimators=100, max_depth=6,
                                                  min_samples_leaf=int(n/100))
DA_learner = DomainAdaptationLearner(models=models,
                                     final_models=final_models,
                                     propensity_model=propensity_model)
# Train DA_learner
DA_learner.fit(y_train, T_train, X=X_train)
# Estimate treatment effects on test data
DA_te = DA_learner.effect(X_test)

# Instantiate Doubly Robust Learner
from econml.dr import DRLearner
outcome_model = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))
pseudo_treatment_model = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))
propensity_model = RandomForestClassifier(n_estimators=100, max_depth=6,
                                                  min_samples_leaf=int(n/100))

DR_learner = DRLearner(model_regression=outcome_model, model_propensity=propensity_model,
                       model_final=pseudo_treatment_model, cv=5)
# Train DR_learner
DR_learner.fit(y, T, X=X)
# Estimate treatment effects on test data
DR_te = DR_learner.effect(X_test)

```

```{python}

### Comparison plot of the different learners
import matplotlib.pyplot as plt

X_test_num = X_test.to_numpy()

plt.figure(figsize=(7, 5))
plt.scatter(X_test_num[:, 2], T_te, label="T-learner")
plt.scatter(X_test_num[:, 2], S_te, label="S-learner")
plt.scatter(X_test_num[:, 2], DA_te, label="DA-learner")
plt.scatter(X_test_num[:, 2], X_te, label="X-learner")
plt.scatter(X_test_num[:, 2], DR_te, label="DR-learner")
plt.xlabel('education degree')
plt.ylabel('Treatment Effect')
plt.legend()
plt.show()
```